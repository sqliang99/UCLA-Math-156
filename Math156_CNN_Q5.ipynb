{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network for MNIST image classficiation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from sklearn.utils.extmath import softmax\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "from tqdm import trange\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src.CNN import CNN, compute_accuracy_metrics, multiclass_accuracy_metrics, list2onehot, onehot2list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (70000, 784)\n",
      "y.shape (70000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEach row of X is a vectroization of an image of 28 x 28 = 784 pixels.  \\nThe corresponding row of y holds the true class label from {0,1, .. , 9}.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random as random\n",
    "\n",
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "# X = X.values  ### Uncomment this line if you are having type errors in plotting. It is loading as a pandas dataframe, but our indexing is for numpy array. \n",
    "X = X / 255.\n",
    "\n",
    "#since the datasize is too big, I am just going to subsample them. \n",
    "\n",
    "#randomlist = random.sample(range(0, 70000), 1500)\n",
    "\n",
    "#X=X[randomlist]\n",
    "#y=y[randomlist]\n",
    "print('X.shape', X.shape)\n",
    "print('y.shape', y.shape)\n",
    "\n",
    "'''\n",
    "Each row of X is a vectroization of an image of 28 x 28 = 784 pixels.  \n",
    "The corresponding row of y holds the true class label from {0,1, .. , 9}.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_padding(img, thickness=1):\n",
    "    # img = a x b image \n",
    "    [a,b] = img.shape\n",
    "    Y = np.zeros(shape=[a+thickness, b+thickness])\n",
    "    r_loc = np.random.choice(np.arange(thickness+1))\n",
    "    c_loc = np.random.choice(np.arange(thickness+1))\n",
    "    Y[r_loc:r_loc+a, c_loc:c_loc+b] = img\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_multiclass_MNIST_padding(list_digits=['0','1', '2'], full_MNIST=[X,y], padding_thickness=10):\n",
    "    # get train and test set from MNIST of given digits\n",
    "    # e.g., list_digits = ['0', '1', '2']\n",
    "    # pad each 28 x 28 image with zeros so that it has now \"padding_thickness\" more rows and columns\n",
    "    # The original image is superimposed at a uniformly chosen location \n",
    "    if full_MNIST is not None:\n",
    "        X, y = full_MNIST\n",
    "    else:\n",
    "        X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "        X = X / 255.\n",
    "    Y = list2onehot(y.tolist(), list_digits)\n",
    "    \n",
    "    idx = [i for i in np.arange(len(y)) if y[i] in list_digits] # list of indices where the label y is in list_digits\n",
    "    \n",
    "    X01 = X[idx,:]\n",
    "    y01 = Y[idx,:]\n",
    "\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_test = [] # list of one-hot encodings (indicator vectors) of each label  \n",
    "    y_train = [] # list of one-hot encodings (indicator vectors) of each label  \n",
    "\n",
    "    for i in trange(X01.shape[0]):\n",
    "        # for each example i, make it into train set with probabiliy 0.8 and into test set otherwise \n",
    "        U = np.random.rand() # Uniform([0,1]) variable\n",
    "        img_padded = random_padding(X01[i,:].reshape(28,28), thickness=padding_thickness)\n",
    "        img_padded_vec = img_padded.reshape(1,-1)\n",
    "        if U<0.8:\n",
    "            X_train.append(img_padded_vec[0,:].copy())\n",
    "            y_train.append(y01[i,:].copy())\n",
    "        else:\n",
    "            X_test.append(img_padded_vec[0,:].copy())\n",
    "            y_test.append(y01[i,:].copy())\n",
    "\n",
    "    X_train = np.asarray(X_train)\n",
    "    X_test = np.asarray(X_test)\n",
    "    y_train = np.asarray(y_train)\n",
    "    y_test = np.asarray(y_test)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 14780/14780 [00:00<00:00, 40820.85it/s]\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.img_x_dim 38\n",
      "LR:0.01, MiniBatch Size:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-3caa43b909fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m            hidden_nodes = 128)\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m CNN0.train(lr = 0.01,\n\u001b[0m\u001b[0;32m     32\u001b[0m            \u001b[0mbeta1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.95\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m            \u001b[0mbeta2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.99\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\work\\2021Spring\\Math 156\\Math 156 hwk7\\src\\CNN.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, lr, beta1, beta2, minibatch_size, num_epochs, verbose, save_path)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[1;31m# update parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m             params, cost = self.adamGD(minibatch=[X,Y],\n\u001b[0m\u001b[0;32m    310\u001b[0m                                        \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# learning rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m                                        \u001b[0mbeta1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\work\\2021Spring\\Math 156\\Math 156 hwk7\\src\\CNN.py\u001b[0m in \u001b[0;36madamGD\u001b[1;34m(self, minibatch, lr, beta1, beta2, cost)\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[1;31m# stride for maxpool = 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[1;31m# maxpool filter dim = 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m             \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[0mdf1_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf2_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdw3_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdw4_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb1_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb2_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb3_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb4_\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\work\\2021Spring\\Math 156\\Math 156 hwk7\\src\\CNN.py\u001b[0m in \u001b[0;36mconv\u001b[1;34m(self, image, label)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;31m############## Forward Operation ###############\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;31m################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mconv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvolution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv_s\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# convolution operation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;31m# print('conv1.shape', conv1.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[0mconv1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;31m# pass through ReLU non-linearity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\work\\2021Spring\\Math 156\\Math 156 hwk7\\src\\CNN.py\u001b[0m in \u001b[0;36mconvolution\u001b[1;34m(self, image, filt, bias, s)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;31m# print('filt.shape', filt.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[0mn_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;31m# image dimensions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m         \u001b[1;31m#n_c, in_dim = image.shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m         \u001b[1;31m# print('image.shape', image.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Simple MNIST binary classification experiments \n",
    "\n",
    "X_train, X_test, y_train, y_test = sample_multiclass_MNIST_padding(list_digits=['0','1'], \n",
    "                                                                   full_MNIST=[X,y],\n",
    "                                                                   padding_thickness=10)\n",
    "\n",
    "# data subsampling \n",
    "train_size = 100\n",
    "\n",
    "idx = np.random.choice(np.arange(len(y_train)), train_size)\n",
    "X_train0 = X_train[idx, :]/np.max(X_train)\n",
    "y_train0 = y_train[idx, :]\n",
    "\n",
    "# preprocessing \n",
    "out = []\n",
    "# populate the tuple list with the data\n",
    "for i in range(X_train0.shape[0]):\n",
    "    item = list((X_train0[i,:].reshape(1,28+10,28+10), y_train0[i,:])) \n",
    "    out.append(item)\n",
    "    \n",
    "# FFNN training\n",
    "CNN0 = CNN(training_data = out,\n",
    "           f = 5, # conv filter dim\n",
    "           f_pool = 2, # maxpool filter dim\n",
    "           num_filt1 = 8, # num filters for the first conv layer\n",
    "           num_filt2 = 8, # num filters for the second conv layer\n",
    "           conv_stride = 1,\n",
    "           pool_stride = 2,\n",
    "           hidden_nodes = 128)\n",
    "\n",
    "CNN0.train(lr = 0.01,\n",
    "           beta1 = 0.95,\n",
    "           beta2 = 0.99,\n",
    "           minibatch_size = 32,\n",
    "           num_epochs = 10,\n",
    "           verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test /= np.max(X_test)\n",
    "print('X_test.shape', X_test.shape)\n",
    "out_test = []\n",
    "index = [2]\n",
    "\n",
    "for i in index:\n",
    "    out_test.append((X_test[i,:].reshape(1,28+10,28+10)))\n",
    "\n",
    "                \n",
    "y_hat,conv1,conv2 = CNN0.predict(image_list=out_test)\n",
    "print(conv1.shape)\n",
    "print(conv2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(conv2[5].reshape(30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(conv1[1].reshape(24,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(conv1[2].reshape(24,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(conv1[3].reshape(24,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
